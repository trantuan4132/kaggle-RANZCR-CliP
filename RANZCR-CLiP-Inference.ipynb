{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    # Data\n",
    "    input_dir = '.'\n",
    "    if os.path.exists('/kaggle/input'):\n",
    "        input_dir = '../input/ranzcr-clip-catheter-line-classification'\n",
    "    img_col = 'StudyInstanceUID'\n",
    "    label_cols = [\n",
    "        'ETT - Abnormal', 'ETT - Borderline', 'ETT - Normal', \n",
    "        'NGT - Abnormal', 'NGT - Borderline', 'NGT - Incompletely Imaged', 'NGT - Normal', \n",
    "        'CVC - Abnormal', 'CVC - Borderline', 'CVC - Normal', \n",
    "        'Swan Ganz Catheter Present',\n",
    "    ]\n",
    "    batch_size = 32\n",
    "    image_size = 512\n",
    "    num_workers = 2\n",
    "    pin_memory = True\n",
    "    seed = 42\n",
    "\n",
    "    # Model\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    in_chans = 3\n",
    "    num_classes = len(label_cols)\n",
    "    drop_path_rate = 0.1\n",
    "    pretrained = False                       # True: load pretrained model, False: train from scratch\n",
    "    checkpoint_path = ''                    # Path to model's pretrained weights\n",
    "    checkpoint_dirs = {'convnext_tiny': [\n",
    "                            'student_checkpoint/fold=0-best-post.pth',\n",
    "                            'student_checkpoint/fold=1-best-post.pth',\n",
    "                            'student_checkpoint/fold=2-best-post.pth',\n",
    "                            'student_checkpoint/fold=3-best-post.pth',\n",
    "                            'student_checkpoint/fold=4-best-post.pth',\n",
    "                        ]}\n",
    "    # checkpoint_dirs = {'convnext_tiny': [\n",
    "    #                         'student_checkpoint/fold=0-best-full.pth',\n",
    "    #                         'student_checkpoint/fold=1-best-full.pth',\n",
    "    #                         'student_checkpoint/fold=2-best-full.pth',\n",
    "    #                         'student_checkpoint/fold=3-best-full.pth',\n",
    "    #                         'student_checkpoint/fold=4-best-full.pth',\n",
    "    #                     ]}\n",
    "    debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RANZCRDataset(Dataset):\n",
    "    def __init__(self, image_dir, df, img_col, label_cols, df_annot=None, \n",
    "                 color_map=None, transform=None, prev_transform=None, return_img='image'):\n",
    "        super(RANZCRDataset, self).__init__()\n",
    "        self.image_dir = image_dir\n",
    "        self.df = df\n",
    "        self.df_annot = df_annot\n",
    "        self.color_map = color_map\n",
    "        self.img_col = img_col\n",
    "        self.label_cols = label_cols\n",
    "        self.transform = transform\n",
    "        self.prev_transform = prev_transform\n",
    "        self.return_img = return_img \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def draw_annotation(self, image, df_annot, img_col, img_id, color_map):\n",
    "        df = df_annot.query(f\"{img_col} == '{img_id}'\")\n",
    "        for index, annot_row in df.iterrows():\n",
    "            data = eval(annot_row['data'])\n",
    "            label = annot_row[\"label\"].split(' - ')\n",
    "            cv2.polylines(image, np.int32([data]), isClosed=False, \n",
    "                          color=color_map[label[0]], thickness=15, lineType=16)\n",
    "            if len(label) > 1 and label[1] != 'Incompletely Imaged':\n",
    "                # x_center, y_center = image.shape[1]/2, image.shape[0]/2\n",
    "                # x, y = min([data[0], data[-1]], key=lambda x: (x[0]-x_center)**2 + (x[1]-y_center)**2)\n",
    "                # cv2.circle(image, (x, y), radius=15, \n",
    "                #             color=color_map[label[1]], thickness=25)\n",
    "                cv2.circle(image, tuple(data[0]), radius=15, \n",
    "                            color=color_map[label[1]], thickness=25)\n",
    "                cv2.circle(image, tuple(data[-1]), radius=15, \n",
    "                            color=color_map[label[1]], thickness=25)\n",
    "        return image\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.df is not None:\n",
    "            row = self.df.iloc[index]\n",
    "            image = cv2.imread(f'{self.image_dir}/{row[self.img_col]}.jpg')[:, :, ::-1].astype(np.uint8)\n",
    "            label = row[self.label_cols].values.astype('float')\n",
    "        else:\n",
    "            image = cv2.imread(f'{self.image_dir}/{os.listdir(self.image_dir)[index]}')[:, :, ::-1].astype(np.uint8)\n",
    "            label = np.zeros(len(self.label_cols))\n",
    "\n",
    "        if self.prev_transform:\n",
    "            image = self.prev_transform(image=image)['image']\n",
    "\n",
    "        # Draw annotation on image if available\n",
    "        annot_image = None\n",
    "        if self.df_annot is not None and self.color_map:\n",
    "            if self.return_img == 'both':\n",
    "                annot_image = image.copy()\n",
    "                annot_image = self.draw_annotation(annot_image, self.df_annot, self.img_col, \n",
    "                                                   row[self.img_col], self.color_map)\n",
    "            elif self.return_img == 'annot_image':\n",
    "                image = self.draw_annotation(image, self.df_annot, self.img_col, \n",
    "                                             row[self.img_col], self.color_map)    \n",
    "\n",
    "        if self.transform:\n",
    "            if annot_image is not None:\n",
    "                transformed = self.transform(image=image, annot_image=annot_image)\n",
    "                image, annot_image = transformed['image'], transformed['annot_image']\n",
    "            else:\n",
    "                image = self.transform(image=image)['image']\n",
    "        return (image, label) if annot_image is None else (image, annot_image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transform(image_size=None, adjust_color=True, is_train=True, include_top=True, additional_targets=None):\n",
    "    transform = []\n",
    "    if image_size:\n",
    "        transform.append(A.Resize(image_size, image_size))\n",
    "    image_size = image_size or 40\n",
    "    if adjust_color:\n",
    "        transform.extend([\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "            A.HueSaturationValue(hue_shift_limit=40, sat_shift_limit=40, val_shift_limit=0, p=0.5),\n",
    "        ])\n",
    "    if is_train:\n",
    "        transform.extend([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            # A.OneOf([\n",
    "            #   A.ImageCompression(),\n",
    "            #   A.Downscale(scale_min=0.1, scale_max=0.15),\n",
    "            # ], p=0.2),\n",
    "            # A.PiecewiseAffine(p=0.2),\n",
    "            # A.Sharpen(p=0.2),\n",
    "            A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.3, rotate_limit=30, border_mode=0, p=0.5),\n",
    "            A.CoarseDropout(max_height=int(image_size*0.2), max_width=int(image_size*0.2), \n",
    "                            min_holes=1, max_holes=4, p=0.5),\n",
    "        ])\n",
    "    if include_top:\n",
    "        transform.extend([\n",
    "            A.Normalize(\n",
    "                mean=[0.5, 0.5, 0.5],\n",
    "                std=[0.5, 0.5, 0.5],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    return A.Compose(transform, additional_targets=additional_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "test_df = pd.read_csv(f'{config.input_dir}/sample_submission.csv')\n",
    "\n",
    "if config.debug:\n",
    "    test_df = test_df.iloc[:100]\n",
    "\n",
    "test_trainsform = build_transform(config.image_size, adjust_color=False, is_train=False, include_top=True)\n",
    "test_dataset = RANZCRDataset(image_dir=f\"{config.input_dir}/test\", df=test_df,\n",
    "                             img_col=config.img_col, label_cols=config.label_cols,\n",
    "                             transform=test_trainsform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config.batch_size,\n",
    "                         num_workers=config.num_workers, pin_memory=config.pin_memory,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RANZCRClassifier(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=False, checkpoint_path='', \n",
    "                 in_chans=3, num_classes=1000, drop_path_rate=0.0, return_features=True):\n",
    "        super(RANZCRClassifier, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained,\n",
    "                                       checkpoint_path=checkpoint_path,\n",
    "                                       drop_path_rate=drop_path_rate)\n",
    "        n_features = self.model.get_classifier().in_features\n",
    "        self.model.reset_classifier(num_classes=0, global_pool='')\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(n_features, num_classes)\n",
    "        self.return_features = return_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.pooling(features).view(bs, -1)\n",
    "        output = self.fc(pooled_features)\n",
    "        return features, output if self.return_features else output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(checkpoint_path=None, fold=None, checkpoint_dir=None, postfix=''):\n",
    "    checkpoint = None\n",
    "    if checkpoint_path:\n",
    "        # Load checkpoint given by the path\n",
    "        if checkpoint_path.startswith('https'):\n",
    "            checkpoint = torch.hub.load_state_dict_from_url(checkpoint_path, \n",
    "                                                            map_location='cpu', \n",
    "                                                            check_hash=True)\n",
    "        else:\n",
    "            checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        print(f\"Loaded checkpoint from {checkpoint_path}\")\n",
    "    elif checkpoint_dir and fold is not None:\n",
    "        # Load checkpoint from the latest one\n",
    "        checkpoint_files = glob.glob(f\"{checkpoint_dir}/fold=*-epoch=*{postfix}.pth\")\n",
    "        checkpoint_files = {f: int(re.search('epoch=(\\d+)', f).group(1)) for f in checkpoint_files \n",
    "                            if int(re.search('fold=(\\d+)', f).group(1)) == fold}\n",
    "        if len(checkpoint_files) > 0:\n",
    "            checkpoint_file = max(checkpoint_files, key=checkpoint_files.get)\n",
    "            checkpoint = torch.load(checkpoint_file, map_location='cpu')\n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "models = []\n",
    "for model_name, checkpoint_dirs in config.checkpoint_dirs.items():\n",
    "    for checkpoint_dir in checkpoint_dirs:\n",
    "        # Initialize model\n",
    "        model = RANZCRClassifier(model_name, pretrained=config.pretrained,\n",
    "                                 checkpoint_path=config.checkpoint_path, \n",
    "                                 in_chans=config.in_chans, num_classes=config.num_classes,\n",
    "                                 drop_path_rate=config.drop_path_rate)\n",
    "        model = model.to(config.device)\n",
    "\n",
    "        # Load weights\n",
    "        checkpoint = load_checkpoint(checkpoint_dir)\n",
    "        if 'auc' in checkpoint:\n",
    "            print(f\"AUC: {checkpoint['auc']}\")\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loader, config):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    tepoch = tqdm(loader)\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, targets) in enumerate(tepoch):\n",
    "            data = data.to(config.device)\n",
    "            _, outputs = model(data)\n",
    "            preds.append(outputs)\n",
    "    return torch.cat(preds).sigmoid().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "preds = []\n",
    "for model in models:\n",
    "    preds.append(predict(model, test_loader, config))\n",
    "preds = np.mean(preds, axis=0)\n",
    "preds = (preds > 0.5).astype('int')\n",
    "test_df[config.label_cols] = preds\n",
    "test_df.to_csv('submission.csv', index=False)\n",
    "test_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
